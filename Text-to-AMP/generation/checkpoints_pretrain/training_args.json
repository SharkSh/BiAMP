{
  "data_dir": "",
  "schedule_sampler": "uniform",
  "lr": 0.0001,
  "weight_decay": 0.0,
  "lr_anneal_steps": 100000,
  "batch_size": 256,
  "microbatch": -1,
  "ema_rate": "0.9999",
  "log_interval": 100,
  "save_interval": 20000,
  "resume_checkpoint": "",
  "use_fp16": false,
  "fp16_scale_growth": 0.001,
  "seed": 101,
  "gradient_clipping": -1.0,
  "eval_interval": 5000,
  "checkpoint_path": "./generation/checkpoints_pretrain",
  "model_path": null,
  "train_ds_path": "./data/seq_text_len_gt.pt",
  "weighted": null,
  "scale": 0.1,
  "image_size": 8,
  "num_channels": 128,
  "num_res_blocks": 2,
  "num_heads": 4,
  "num_heads_upsample": -1,
  "attention_resolutions": "16,8",
  "dropout": 0.0,
  "learn_sigma": false,
  "sigma_small": false,
  "class_cond": false,
  "diffusion_steps": 2000,
  "timestep_respacing": "",
  "noise_schedule": "sqrt",
  "use_kl": false,
  "rescale_learned_sigmas": true,
  "use_scale_shift_norm": true,
  "predict_xstart": true,
  "rescale_timesteps": true,
  "use_checkpoint": false,
  "model_arch": "skip_transformer",
  "in_channel": 1024,
  "out_channel": 1024,
  "training_mode": "emb",
  "vocab_size": 66,
  "config_name": "bert-base-uncased",
  "experiment_mode": "lm",
  "logits_mode": 1,
  "modality": "pep_emd",
  "emb_scale_factor": 1.0,
  "noise_level": 0.0,
  "preprocessing_num_workers": 1
}